{
 "metadata": {
  "name": "",
  "signature": "sha256:92332c8b24e4b321651029ec69a6b8a0477bf4eeba2dcd1796616ee3a0705f20"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Pandas and Files\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<align=\"left\">We will use a Python package called \"pandas\" for most of our file manipulations in this class. Pandas does a lot of important things, most importantly it gives us the DataFrame object which gives us a very useful Python representation of of tabular (table-like) data. By convention, \"pandas\" is typically imported under the alias \"pd\" so that less typing is needed to reference it. To import pandas under the alias \"pd\": "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Creating a DataFrame from a file\n",
      "<align=\"left\">In the examples below we will be working with the following files with I have downloaded to the `C:\\Users\\measure_a\\Downloads` directory of my computer:\n",
      "* [msha.csv](https://www.dropbox.com/s/nffyygpz243xjwt/msha.csv)\n",
      "* [msha.txt](https://www.dropbox.com/s/a11hwwp8qtqfdmz/msha.txt)\n",
      "* [msha.xlsx](https://www.dropbox.com/s/schtzyzbelc4x1c/msha.xlsx)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To read a csv file into a dataframe\n",
      "df = pd.read_csv(r'C:\\Users\\measure_a\\Downloads\\msha.csv')\n",
      "\n",
      "# To read a file with an arbitrary column separator into a dataframe\n",
      "# Note: in this case separator is the tab character (represented by \"\\t\"). \n",
      "df = pd.read_csv(r'C:\\Users\\measure_a\\Downloads\\msha.txt', sep=\"\\t\")\n",
      "\n",
      "# To read an xls files into a dataframe\n",
      "df = pd.read_excel(r'C:\\Users\\measure_a\\Downloads\\msha.xlsx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'read_excel'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-15-addd129be507>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# To read an xls files into a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\measure_a\\Downloads\\msha.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'read_excel'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Inspecting a DataFrame\n",
      "The first thing you should do after loading a DataFrame is to inspect it to verify that it was loaded correctly. One quick way to do this is to check the first few rows of our dataframe with the df.head() method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also check the last few rows of the file with df.tail()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we can check the number of rows in our dataframe using the built-in Python function len(). Here we see the dataframe contains 41,035 rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Adding a unique ID\n",
      "\n",
      "Before we go much further, let's add a column that uniquely identifies each of these cases. One way to do this is as follows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a list of unique ID's that is as long as the number of rows in our dataframe\n",
      "ids = range(len(df))\n",
      "\n",
      "# Create a new column called 'UNIQUE_ID' which will hold this list\n",
      "df['UNIQUE_ID'] = ids\n",
      "df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Splitting and Joining by Rows\n",
      "Splitting the top rows into one dataframe, and the bottom into another"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_part1 = df[0:10000]\n",
      "df_part2 = df[10000:]\n",
      "\n",
      "print('df_part1 contains the first %s rows' % len(df_part1))\n",
      "print('df_part2 contains the last %s rows' % len(df_part2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Stacking the dataframes one on top of the other"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.concat([df_part1, df_part2])\n",
      "print(len(df))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Subsetting by column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_part_columns = df[['UNIQUE_ID', 'INJ_BODY_PART', 'INJ_BODY_PART_CD', 'NARRATIVE']]\n",
      "df_other_columns = df[['UNIQUE_ID', 'MINE_ID', 'FIPS_STATE_CD', 'ACCIDENT_DT']]\n",
      "\n",
      "df_part_columns.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_other_columns.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Merging the columns back together. The merge method accepts a number of arguments including <i>on</i> which is a list that defines the columns on which the two dataframes will be merged. In this case only the column \"UNIQUE_ID\" is needed to match the dataframes, but for BLS data it would not be uncommon to use ['SURVEY_YEAR', 'LDB_NUMBER'] instead."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.merge(df_part_columns, df_other_columns, on=['UNIQUE_ID'])\n",
      "df.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Working with columns\n",
      "\n",
      "We can refer to a single column in a dataframe using the syntax <i>df[\"column_name\"]</i>. For example, to examine just the 'NARRATIVE' column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['NARRATIVE'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Adding columns\n",
      "\n",
      "Previously, we created a simple function that determines whether a narrative refers to a foot injury or not. It looked something like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def foot_or_not(narrative):\n",
      "    narrative = narrative.lower()\n",
      "    words = re.findall('\\w+', narrative)\n",
      "    if 'foot' in words:\n",
      "        return True\n",
      "    elif 'feet' in words:\n",
      "        return True\n",
      "    else:\n",
      "        return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To add a new column to our dataframe that results from applying this function to each individual narrative we can do the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['FOOT_INJURY'] = df['NARRATIVE'].apply(foot_or_not)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Converting DataFrames to other outputs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save DataFrame as a CSV file\n",
      "df.to_csv('coded_MSHA.csv')\n",
      "\n",
      "# save DataFrame as a tab delimited CSV file\n",
      "df.to_csv('coded_MSHA.tsv', sep='\\t')\n",
      "\n",
      "# save DataFrame as an Excel file\n",
      "df.to_excel('coded_MSHA.xlsx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also convert DataFrames to a list of dictionaries.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pprint\n",
      "\n",
      "rows = df.to_dict(outtype='records')\n",
      "\n",
      "# pprint is like print but it formats the output to be more readable\n",
      "pprint.pprint(rows[0:3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}