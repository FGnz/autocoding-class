{
 "metadata": {
  "name": "",
  "signature": "sha256:549c0733d00138da3144e190b8369a90600740ccde49ee369648e9e0ac05cbf1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Experimental Setup\n",
      "Once you have gathered the data for your autocoder, the first thing you should do is randomly divide it into 3 datasets: training, validation, and test. The training data will be used to train a variety of different autocoders, the validation data will be used to choose the best of these, and the test data will only be used (ideally, once) at the very end to measure how well your best autocoder works.\n",
      "\n",
      "It's important to do this because the techniques we will be using have a tremendous ability to learn, so much so that in some cases they simply memorize the training data. For example, the computer might see that the name \"Wiatt Springfield\" is only associated with a \"foot\" injury in the training data and assume this name always indicates a foot injury. This phenomenon is called \"overfitting\" and it is the bane of many a researcher. Our setup helps us detect and prevent this.  \n",
      "\n",
      "The exact ratio of cases allocated to the training, validation, and test datasets is usually not too important, a 50%/25%/25% split is not unusual, nor is a 90%/5%/5% split. Ultimately, the tradeoff is that more training data allows us to build better initial models, more validation data allows us to more precisely determine the best of our competing models, and more test data allows us to more precisely measure the quality of our final model. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below, we read a csv file into a DataFrame, randomly permute the indexes of that DataFrame, and then set the first 10,000 rows aside for test data, the next 10,000 for validation, and the remaining 20,000+ for training."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# read the csv file into a DataFrame\n",
      "df = pd.read_csv(r'C:\\Users\\measure_a\\Desktop\\autocoding-class\\msha.csv')\n",
      "\n",
      "# randomly permute the indexes of the DataFrame\n",
      "df.reindex(np.random.permutation(df.index))\n",
      "\n",
      "# split the DataFrame into separate test, validation, and training DataFrames\n",
      "df_test = df[0:10000]\n",
      "df_validation = df[10000:20000]\n",
      "df_training = df[20000:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Feature Extraction\n",
      "A critical step (perhaps the most important) in building our machine learning autocoder is determining the relevant inputs for our task and encoding these in a way that will be both computationally efficient, and easy to learn. \n",
      "\n",
      "For text classification tasks such as ours, a very simple approach that often works very well is known as the bag-of-words-representation.\n",
      "\n",
      "The basic idea is to convert each example (i.e. narrative) into a giant vector (list of numbers), where each position in the vector corresponds to one of the  words that occurs in our training data, and the value at that position indicates something about that word's occurence in the specific example. Often, we use a value of 1 to indicate that the word is present in the narrative, and a 0 to indicate it is not. The resulting vector is known as a feature vector because it represents the features of our data that we consider relevant for our task.\n",
      "\n",
      "Below, we use scikit-learn to convert the injury narratives from our training data into a matrix (table of numbers), with each row of that matrix corresponding to the vector produced by our bag-of-words representation of an example. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "# Create an instance of the CountVectorizer object\n",
      "vectorizer = CountVectorizer()\n",
      "# Use the narratives in our training data to create the vocabulary that will\n",
      "# be represented by our feature vectors. This is remembered by the vectorizer.\n",
      "vectorizer.fit(df_training['NARRATIVE'])\n",
      "# Convert the training narratives into their matrix representation.\n",
      "x_training = vectorizer.transform(df_training['NARRATIVE'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below, an examination of the feature matrix shows it consists of 21,035 rows (i.e. it represents 21,035 training examples), and 12,441 columns (words in our vocabulary)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(x_training.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(21035, 12441)\n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also examine the matrix directly. Below, we examine the vector represeting our first example. All of the visible entries are 0 which is not unexpected. Of the 12,441 elements in the vector representing our first example, only 18 have a non-zero value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_training[0].todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "matrix([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Selecting and Fitting the Model\n",
      "Another important consideration in building a machine learning autocoder is selecting and fitting our model. The model defines the ways in which our features can relate to the codes that will be assigned, our fitting procedure decides how the details of the model will ultimately be learned.\n",
      "\n",
      "Below, we use a regularized Logistic Regression model, which has been shown\n",
      "to work well on many text classification tasks. The regularization hyperparameter C controls how closely we allow the model to fit the training data. If C is too high the model will tend to \"overfit\". If it is too low, the model may fail to learn important relationships between the features and the codes. \n",
      "\n",
      "There is only one way to find the optimal value for C: experimentation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "# y_training contains the codes associated with our training narratives\n",
      "y_training = df_training['INJ_BODY_PART_CD']\n",
      "# we create an instance of the LogisticRegression model\n",
      "clf = LogisticRegression(C=1.0)\n",
      "# we fit the model to our training data (ie. we calculate the model parameters)\n",
      "clf.fit(x_training, y_training)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Like our other outputs, we can inspect the Logistic Regression model. The most important attribute of the model is the coefficients, which show how strongly our various features are related to our various codes. Like our feature values, these coefficients are also stored in a matrix. \n",
      "\n",
      "Below, we see that the coefficients matrix consists of 45 rows, one for each of the possible codes, and 12,441 columns, one for each of our features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(clf.coef_.shape)\n",
      "print(clf.coef_[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(45L, 12441L)\n",
        "[ -1.49989797e-03  -8.32565807e-06  -2.57146849e-07 ...,  -4.23024936e-04\n",
        "   3.20631484e-08   3.24435833e-09]\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Evaluation\n",
      "\n",
      "Already we have seen that there are many different ways to build our autocoder, the regularization parameter (C) alone has infinite values. In fact, there are many other things we can vary, some of which we will discuss later. To choose amongst these options we must try them and measure their quality in some way. This is the purpose of our validation data.\n",
      "\n",
      "Below, we use our vectorizer to convert the narratives from our valadition data into into a feature matrix using the same encoding scheme used for our training data. We then use our trained LogisticRegression classifier to predict codes for these narratives, and compare these to the \"true\" codes already assigned to the narratives by MSHA."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Convert the validation narratives to a feature matrix\n",
      "x_validation = vectorizer.transform(df_validation['NARRATIVE'])\n",
      "# Generate predicted codes for our validation narratives\n",
      "y_validation_pred = clf.predict(x_validation)\n",
      "# Calculate how accurately these match the true codes\n",
      "y_validation = df_validation['INJ_BODY_PART_CD']\n",
      "accuracy = accuracy_score(y_validation, y_validation_pred)\n",
      "print('accuracy = %s' % (accuracy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy = 0.75\n"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our validation data says we have 75% accuracy, not bad considering we've done almost no work. It's perfectly possible that human accuracy is near 75% on this task, although that's a study for another time. \n",
      "\n",
      "What if we had been foolish and evaluated our model only on the training data?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_training_pred = clf.predict(x_training)\n",
      "accuracy = accuracy_score(y_training, y_training_pred)\n",
      "print('accuracy = %s' % (accuracy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy = 0.954171618731\n"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yikes! Evaluating on our training data would have told us we were coding at 95% accuracy when really we only get 75% accuracy on the validation data. A large gap between accuracy on the training data and validation data is an indicator that overfitting is occurring, and 20% is a very large gap. This suggests we might be able to improve our model by reducing overfitting.\n",
      "\n",
      "There are a number of ways to do this: we might reduce the number of features in our model, we might gather more training data, or we might use a different model that is more resistant to overfitting. In this case we will reduce the regularization hyperparameter C, which tends to also reduce overfitting. Below, we train a new model with C set at 0.1 and re-evaluate it's performance on our training and validation data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = LogisticRegression(C=0.1)\n",
      "clf.fit(x_training, y_training)\n",
      "\n",
      "y_training_pred = clf.predict(x_training)\n",
      "training_accuracy = accuracy_score(y_training, y_training_pred)\n",
      "print('accuracy on training data is: %s' % training_accuracy)\n",
      "\n",
      "y_validation_pred = clf.predict(x_validation)\n",
      "validation_accuracy = accuracy_score(y_validation, y_validation_pred)\n",
      "print('accuracy on validation data is: %s' % validation_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy on training data is: 0.847254575707\n",
        "accuracy on validation data is: 0.7569\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Decreasing the hyperparameter C has reduced our overfitting quite a bit. The accuracy on the training data has fallen substantially (but who cares, we don't need to predict data we already know the codes for). More importantly, our accuracy on the validation data seems to have improved slightly. This is likely to be a better model than what we were using previously.\n",
      "\n",
      "There are many other ways we might adjust our model. For example, we might change the way we convert our narratives into feature vectors. This is controlled by the vectorizer we use, in this case CountVectorizer. The [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVr.html) online shows there are many ways this might be modified, we illustrate a few below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### minimum document frequency\n",
      "By default, CountVectorizer includes any feature (i.e. word) that occurs in our training data as a feature in our feature vector. We can use the min_df argument to specify that features should only be included in the feature vector if they occur in at least X different documents. Below, we specify that a feature should only be included if it occurs in at least 2 different documents. Previously this resulted in a feature vector that included 12,441 features. Now, we only get 7,106."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer1 = CountVectorizer(min_df=2)\n",
      "x_training = vectorizer1.fit_transform(df_training['NARRATIVE'])\n",
      "x_training.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "(21035, 7106)"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### n-grams\n",
      "Another CountVectorizer default is to only include individual words as features. Sometimes it's also useful to include short sequences of words, 2 word sequences (called bigrams) and ocassionaly, 3 word sequences called trigrams. Below, we tell the vectorizer to create features for all individual words and word pairs that occur in at least 2 examples in our training data. This has the effect of dramatically increasing the number of features in our feature vector to 56,704! Be careful with this, you can very easily end up with a feature matrix larger than your computer can handle."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer2 = CountVectorizer(min_df=2, ngram_range=(1,2))\n",
      "x_training = vectorizer2.fit_transform(df_training['NARRATIVE'])\n",
      "print(x_training.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(21035, 56704)\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On a typical machine learning project you will likely spend a lot of time tweaking your model and retraining it, as we have done above. Eventually you will settle on the best version (as measured against your validation data). You will then measure it's performance on the test data to get a final measure of performance."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Saving the Model\n",
      "\n",
      "Suppose we have settled on our final autocoder. This probably took quite a bit of time to develop. The first thing we want to do is save it. We need to save both vectorizer used to encode our data, and the model used to classify it. Below, we do this using the Python module `joblib`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.externals import joblib\n",
      "\n",
      "# save the classifier object as LRclf.pkl\n",
      "joblib.dump(clf, filename='LRclf.pkl')\n",
      "# save the vectorizer object as vectorizer.pkl\n",
      "joblib.dump(vectorizer, filename='vectorizer.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 145,
       "text": [
        "['vectorizer.pkl']"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Later, we can load these back as below. Note: we must first import any objects or functions used by our pickled files, otherwise they will fail to load."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.externals import joblib\n",
      "# import the objects used by our saved vectorizer and classifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "# load the classifier\n",
      "clf = joblib.load(filename='LRclf.pkl')\n",
      "# load the vectorizer\n",
      "vectorizer = joblib.load(filename='vectorizer.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Using the Autocoder\n",
      "\n",
      "There are a number of ways we might use our newly created autocoder. The simplest option is to just automatically assign the codes. Suppose for example, that our test dataset is really just a set of uncoded narratives. We might code it as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_test = vectorizer.transform(df_test['NARRATIVE'])\n",
      "y_test_pred = clf.predict(x_test)\n",
      "\n",
      "df_test['Autocode']=y_test_pred\n",
      "df_test.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ACCIDENT_DT</th>\n",
        "      <th>FIPS_STATE_CD</th>\n",
        "      <th>INJ_BODY_PART</th>\n",
        "      <th>INJ_BODY_PART_CD</th>\n",
        "      <th>MINE_ID</th>\n",
        "      <th>NARRATIVE</th>\n",
        "      <th>Autocode</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 2010-08-10 00:00:00</td>\n",
        "      <td>  8</td>\n",
        "      <td> SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)</td>\n",
        "      <td> 450</td>\n",
        "      <td>  503800</td>\n",
        "      <td> Cleaning out Gabion Grizzly,  Rocks get Jammed...</td>\n",
        "      <td> 450</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2010-06-09 00:00:00</td>\n",
        "      <td> 36</td>\n",
        "      <td> SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)</td>\n",
        "      <td> 450</td>\n",
        "      <td>  600026</td>\n",
        "      <td> Injured was walking in the pit area, stepped o...</td>\n",
        "      <td> 450</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2012-08-20 00:00:00</td>\n",
        "      <td> 24</td>\n",
        "      <td>   HIPS (PELVIS/ORGANS/KIDNEYS/BUTTOCKS)</td>\n",
        "      <td> 440</td>\n",
        "      <td> 1800761</td>\n",
        "      <td> Employee, parked s/c on grade at 16-Block #3 E...</td>\n",
        "      <td> 420</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 2013-10-29 00:00:00</td>\n",
        "      <td>  4</td>\n",
        "      <td>                                   ANKLE</td>\n",
        "      <td> 520</td>\n",
        "      <td>  200024</td>\n",
        "      <td> Contractor employee working as a carpenter mis...</td>\n",
        "      <td> 520</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 2011-11-19 00:00:00</td>\n",
        "      <td> 32</td>\n",
        "      <td>                         FINGER(S)/THUMB</td>\n",
        "      <td> 340</td>\n",
        "      <td> 2602512</td>\n",
        "      <td> The employee's finger was pinched between the ...</td>\n",
        "      <td> 340</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 147,
       "text": [
        "           ACCIDENT_DT  FIPS_STATE_CD  \\\n",
        "0  2010-08-10 00:00:00              8   \n",
        "1  2010-06-09 00:00:00             36   \n",
        "2  2012-08-20 00:00:00             24   \n",
        "3  2013-10-29 00:00:00              4   \n",
        "4  2011-11-19 00:00:00             32   \n",
        "\n",
        "                             INJ_BODY_PART  INJ_BODY_PART_CD  MINE_ID  \\\n",
        "0  SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)               450   503800   \n",
        "1  SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)               450   600026   \n",
        "2    HIPS (PELVIS/ORGANS/KIDNEYS/BUTTOCKS)               440  1800761   \n",
        "3                                    ANKLE               520   200024   \n",
        "4                          FINGER(S)/THUMB               340  2602512   \n",
        "\n",
        "                                           NARRATIVE  Autocode  \n",
        "0  Cleaning out Gabion Grizzly,  Rocks get Jammed...       450  \n",
        "1  Injured was walking in the pit area, stepped o...       450  \n",
        "2  Employee, parked s/c on grade at 16-Block #3 E...       420  \n",
        "3  Contractor employee working as a carpenter mis...       520  \n",
        "4  The employee's finger was pinched between the ...       340  "
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another option is to be more selective. Our LogisticRegression model has the nice property that it can tell us not only which codes it thinks are best, but it can also tell us how likely those codes are to be correct. We might use this information to only assign codes that exceed a certain likelihood of being correct, alternatively we could use this information to provide \"suggestions\" indicating the codes most likely to be correct.\n",
      "\n",
      "To get the probabilities, we use the predict_proba() method of our Logistic Regression classifier. For each of the examples we run predict_proba() on, we will get a sequence showing how confident the model is that each of the 45 codes should be assigned to it. \n",
      "\n",
      "Below, we run predict_proba() on our 10,000 example test dataset. The result is a 10,000 row matrix (one for each example), with 45 columns (one for each code). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_prob = clf.predict_proba(x_test)\n",
      "print('The shape of the pred_prob matrix is: %s' % str(y_pred_prob.shape))\n",
      "print('The probabilities for the first example are:\\n%s' % y_pred_prob[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The shape of the pred_prob matrix is: (10000L, 45L)\n",
        "The probabilities for the first example are:\n",
        "[  2.99337247e-03   1.80713766e-03   2.92682390e-05   1.78588683e-03\n",
        "   7.51524490e-04   9.68686187e-03   3.40910209e-03   5.67341962e-03\n",
        "   2.10892481e-03   1.87632607e-03   1.62990013e-03   1.17031671e-03\n",
        "   4.53725498e-05   1.77538181e-03   1.17880611e-03   1.55684617e-04\n",
        "   1.54423847e-03   1.22558109e-02   1.18574200e-03   4.08205285e-03\n",
        "   7.03025494e-04   1.48212456e-02   8.05213068e-03   1.51299637e-02\n",
        "   3.19116083e-03   8.04380671e-05   2.10056933e-03   1.00199372e-02\n",
        "   2.93361588e-03   4.64167923e-03   7.80632832e-01   5.55538895e-03\n",
        "   1.14233350e-03   8.25702542e-03   3.87357177e-03   3.42327394e-03\n",
        "   1.96844849e-03   3.64346460e-03   4.38349081e-03   2.79819921e-03\n",
        "   7.69316616e-03   5.82707276e-03   5.24511744e-02   1.91823920e-05\n",
        "   1.51247968e-03]\n"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The position in the vector indicates the code the probability corresponds to. To recover just the probability and position of the most likely code, we can do the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get a sequence indicating the position with the highest probability for each row\n",
      "top_positions = y_pred_prob.argmax(axis=1)\n",
      "\n",
      "codes = []\n",
      "probabilities = []\n",
      "# loop through each example and retrieve the best code and it's probability\n",
      "# if the probability exceeds .75, add it as an autocode, otherwise leave it alone\n",
      "for n, pos in enumerate(top_positions):\n",
      "    code = clf.classes_[pos]\n",
      "    prob = y_pred_prob[n][pos]\n",
      "    probabilities.append(prob)\n",
      "    if prob > .75:\n",
      "        codes.append(code)\n",
      "    else:\n",
      "        codes.append('')\n",
      "\n",
      "# Add the autocodes to our DataFrame\n",
      "df_test['Autocode'] = codes\n",
      "# Add the probabilities to our DataFrame\n",
      "df_test['Probability'] = probabilities\n",
      "# Show selected columns of our updated DataFrame\n",
      "df_test[['INJ_BODY_PART', 'INJ_BODY_PART_CD', 'Autocode', 'Probability']].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>INJ_BODY_PART</th>\n",
        "      <th>INJ_BODY_PART_CD</th>\n",
        "      <th>Autocode</th>\n",
        "      <th>Probability</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)</td>\n",
        "      <td> 450</td>\n",
        "      <td> 450</td>\n",
        "      <td> 0.780633</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)</td>\n",
        "      <td> 450</td>\n",
        "      <td>    </td>\n",
        "      <td> 0.746746</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>   HIPS (PELVIS/ORGANS/KIDNEYS/BUTTOCKS)</td>\n",
        "      <td> 440</td>\n",
        "      <td>    </td>\n",
        "      <td> 0.100461</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>                                   ANKLE</td>\n",
        "      <td> 520</td>\n",
        "      <td> 520</td>\n",
        "      <td> 0.800249</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>                         FINGER(S)/THUMB</td>\n",
        "      <td> 340</td>\n",
        "      <td> 340</td>\n",
        "      <td> 0.823858</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 149,
       "text": [
        "                             INJ_BODY_PART  INJ_BODY_PART_CD Autocode  \\\n",
        "0  SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)               450      450   \n",
        "1  SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)               450            \n",
        "2    HIPS (PELVIS/ORGANS/KIDNEYS/BUTTOCKS)               440            \n",
        "3                                    ANKLE               520      520   \n",
        "4                          FINGER(S)/THUMB               340      340   \n",
        "\n",
        "   Probability  \n",
        "0     0.780633  \n",
        "1     0.746746  \n",
        "2     0.100461  \n",
        "3     0.800249  \n",
        "4     0.823858  "
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extras\n",
      "\n",
      "Scikit-learn provides a wide variety of powerful tools that we didn't have time to cover in this class, including many different learning algorithms and utilities for feature and model selection. To learn more, see the official and very extensive [online documentation](http://scikit-learn.org/stable/index.html)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}